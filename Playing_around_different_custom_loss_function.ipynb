{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Playing around different custom loss function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9Je/nPg24gVj27JGISWnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jahid1990/Deep-Learning-Applications-R-Python/blob/master/Playing_around_different_custom_loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxFWCKLEIwFX"
      },
      "source": [
        "# Loading Some required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpCZAWi4IZcp"
      },
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense,Conv1D,MaxPooling1D,Flatten,Concatenate\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras import metrics\n",
        "import keras.backend as K"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QgMU_hpI6ft"
      },
      "source": [
        "# Dummy dataset creation\n",
        "\n",
        "To have better intuition, lets create a small dataset having both discrete and continuous dependent variable(y_train). Making sure that dataset is applicable for all sort of loss functions we are going to explore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCw3gfTzI51x",
        "outputId": "c573c660-c430-40e6-9336-d62192aec517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_train=np.random.rand(100,5)\n",
        "y_train=np.concatenate((np.random.randint(0,2,(100,2)),np.random.rand(100,4)),axis=1)\n",
        "print(\"shape of x_train:\"+str(x_train.shape))\n",
        "print(\"shape of y_train:\"+str(y_train.shape))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train:(100, 5)\n",
            "shape of y_train:(100, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRv7icvpIugW",
        "outputId": "ebf87e47-d2c0-40db-9b18-86f5d7044994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "print(\" x_train:\")\n",
        "print(x_train[:3,:]) # first 3 rows of explanatory variables (x_train) \n",
        "print(\" y_train:\")\n",
        "print(y_train[:3,:]) # first 3 rows of indenpendent variables (y_train)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " x_train:\n",
            "[[0.58762746 0.49815876 0.06610818 0.51478354 0.58487054]\n",
            " [0.94996571 0.06768403 0.77131331 0.33419011 0.14821091]\n",
            " [0.42817061 0.32619562 0.52025564 0.72479127 0.51587583]]\n",
            " y_train:\n",
            "[[0.         0.         0.47507594 0.1692404  0.47550315 0.82312835]\n",
            " [0.         0.         0.56238008 0.34338669 0.0205376  0.93589996]\n",
            " [0.         0.         0.74545935 0.41756426 0.62706896 0.80462387]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1k6TLpf2F0h",
        "outputId": "97294eb3-5b0c-4ced-ffe4-9d9848eef1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def custom_act(x):\n",
        "    e_x = 1/(1+tf.keras.backend.exp(-x))\n",
        "    return e_x\n",
        "x = np.array([[ 0.50839931,  0.49767588,  0.51260159]])\n",
        "#softmax(x)\n",
        "K.sigmoid(x_train)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 5), dtype=float64, numpy=\n",
              "array([[0.64282059, 0.62202654, 0.51652103, 0.62592718, 0.64218734],\n",
              "       [0.72110828, 0.51691455, 0.68380492, 0.58277854, 0.53698505],\n",
              "       [0.60543674, 0.58083343, 0.62720754, 0.67366121, 0.62618289],\n",
              "       [0.60543924, 0.70727598, 0.66807792, 0.55530073, 0.55390834],\n",
              "       [0.64108378, 0.71991134, 0.53439936, 0.69492569, 0.65378695],\n",
              "       [0.69593637, 0.61883176, 0.53997433, 0.56129917, 0.53650323],\n",
              "       [0.6134788 , 0.6221689 , 0.55542781, 0.71856159, 0.58802779],\n",
              "       [0.56328009, 0.68836041, 0.68350647, 0.69822832, 0.60701771],\n",
              "       [0.53382252, 0.64781493, 0.71070425, 0.64695805, 0.67060554],\n",
              "       [0.68977872, 0.66410023, 0.70315767, 0.60368075, 0.50688958],\n",
              "       [0.71321984, 0.59592568, 0.63209177, 0.71931907, 0.67383158],\n",
              "       [0.59249422, 0.66196909, 0.67633444, 0.62810846, 0.65532387],\n",
              "       [0.62068505, 0.66618083, 0.52321136, 0.55596442, 0.53031105],\n",
              "       [0.65952364, 0.53986063, 0.66470711, 0.58939667, 0.50449298],\n",
              "       [0.67865791, 0.56351612, 0.56306587, 0.63480792, 0.68730789],\n",
              "       [0.64430071, 0.63940736, 0.51704052, 0.59888215, 0.59222703],\n",
              "       [0.50310392, 0.50780177, 0.68378549, 0.69530138, 0.6253201 ],\n",
              "       [0.70705225, 0.52035234, 0.53323051, 0.52920119, 0.58463904],\n",
              "       [0.62384248, 0.60383913, 0.69087321, 0.71982466, 0.62296623],\n",
              "       [0.57383766, 0.65122342, 0.511656  , 0.66610388, 0.51793159],\n",
              "       [0.54676933, 0.69695673, 0.53096994, 0.61470158, 0.57755403],\n",
              "       [0.69285783, 0.67646275, 0.67467274, 0.68106572, 0.71105867],\n",
              "       [0.66103992, 0.68405165, 0.50310302, 0.67180939, 0.62215794],\n",
              "       [0.61171218, 0.52844771, 0.52236154, 0.58310577, 0.54156908],\n",
              "       [0.59565691, 0.59455694, 0.68898914, 0.5843011 , 0.63914693],\n",
              "       [0.57291181, 0.60537691, 0.54911771, 0.58074312, 0.5762325 ],\n",
              "       [0.67536506, 0.60137598, 0.54690365, 0.66741532, 0.53686908],\n",
              "       [0.57862884, 0.70550787, 0.57012939, 0.66193084, 0.72927299],\n",
              "       [0.5872    , 0.61494894, 0.59899248, 0.53947452, 0.5122653 ],\n",
              "       [0.62610074, 0.5822688 , 0.51572734, 0.54674513, 0.5861094 ],\n",
              "       [0.60570473, 0.65130248, 0.69929869, 0.69786538, 0.69066304],\n",
              "       [0.57909111, 0.58928159, 0.66831493, 0.57480074, 0.72663645],\n",
              "       [0.53431307, 0.72551791, 0.50003865, 0.72134735, 0.65700771],\n",
              "       [0.57403232, 0.59356699, 0.70121839, 0.56503144, 0.52013888],\n",
              "       [0.69183937, 0.65273032, 0.56464348, 0.61961762, 0.6213466 ],\n",
              "       [0.65445424, 0.54866041, 0.66726676, 0.65047148, 0.52302656],\n",
              "       [0.56267749, 0.60834478, 0.69446409, 0.59673895, 0.60554432],\n",
              "       [0.64604141, 0.68018823, 0.56028105, 0.64807765, 0.57796309],\n",
              "       [0.57265867, 0.64552094, 0.71315884, 0.5677124 , 0.69431149],\n",
              "       [0.51371784, 0.5544299 , 0.62515619, 0.52810374, 0.56064504],\n",
              "       [0.69048239, 0.6789123 , 0.5793717 , 0.72131611, 0.54031614],\n",
              "       [0.68219923, 0.59208183, 0.55882385, 0.55214177, 0.51951141],\n",
              "       [0.67168993, 0.53327702, 0.68451394, 0.50158311, 0.67420765],\n",
              "       [0.52470208, 0.73080827, 0.67886187, 0.55233793, 0.51043083],\n",
              "       [0.52693037, 0.65509089, 0.7051569 , 0.62627632, 0.65545787],\n",
              "       [0.73087853, 0.58262254, 0.57427574, 0.72820486, 0.68759348],\n",
              "       [0.70907797, 0.70568657, 0.61840396, 0.72060159, 0.56996489],\n",
              "       [0.7159796 , 0.53570557, 0.66098857, 0.66585672, 0.6961306 ],\n",
              "       [0.67401359, 0.57423393, 0.55320884, 0.72377212, 0.73097097],\n",
              "       [0.67038778, 0.63569093, 0.62034548, 0.53588073, 0.57959973],\n",
              "       [0.66596355, 0.66936319, 0.64776345, 0.58090042, 0.61251058],\n",
              "       [0.55167941, 0.57231856, 0.53110443, 0.59527539, 0.62299917],\n",
              "       [0.57981071, 0.65829135, 0.71501741, 0.56580896, 0.65383852],\n",
              "       [0.54774298, 0.63706783, 0.69315536, 0.5594556 , 0.57225443],\n",
              "       [0.55312855, 0.65403458, 0.5070091 , 0.69542102, 0.69251171],\n",
              "       [0.5678895 , 0.69567659, 0.5671565 , 0.6435471 , 0.65378701],\n",
              "       [0.66878019, 0.70874248, 0.69552138, 0.67844662, 0.53868512],\n",
              "       [0.70160601, 0.71125331, 0.55807973, 0.53680778, 0.51485118],\n",
              "       [0.57732526, 0.61748998, 0.63758172, 0.71137173, 0.67867926],\n",
              "       [0.66726777, 0.62084882, 0.55630891, 0.65867143, 0.56093639],\n",
              "       [0.68043435, 0.55378806, 0.53267601, 0.54641401, 0.620399  ],\n",
              "       [0.58032631, 0.6905334 , 0.6639742 , 0.64067684, 0.662816  ],\n",
              "       [0.68848715, 0.65036014, 0.6618321 , 0.65223276, 0.65170332],\n",
              "       [0.53887399, 0.51620197, 0.72848008, 0.63002492, 0.66651179],\n",
              "       [0.58939368, 0.67503874, 0.64084617, 0.62655039, 0.61865299],\n",
              "       [0.69728749, 0.56070827, 0.71198095, 0.56865751, 0.60180126],\n",
              "       [0.61773808, 0.55256458, 0.67224548, 0.68811525, 0.52805222],\n",
              "       [0.67427437, 0.66801469, 0.69038117, 0.51367019, 0.56525489],\n",
              "       [0.63789227, 0.55638601, 0.53981685, 0.67623078, 0.71483067],\n",
              "       [0.6127005 , 0.70488174, 0.70291268, 0.70526496, 0.6777389 ],\n",
              "       [0.69676526, 0.65012239, 0.70414479, 0.69278451, 0.65154517],\n",
              "       [0.57476172, 0.54047197, 0.62378919, 0.57724044, 0.50015646],\n",
              "       [0.70187614, 0.71837833, 0.57389979, 0.63305572, 0.6312695 ],\n",
              "       [0.56610636, 0.52655264, 0.5950553 , 0.52899685, 0.70359861],\n",
              "       [0.580636  , 0.52394968, 0.59024224, 0.52302108, 0.60532626],\n",
              "       [0.64867385, 0.60278986, 0.67952818, 0.69296961, 0.62649492],\n",
              "       [0.58632066, 0.65142828, 0.52604272, 0.624531  , 0.52044604],\n",
              "       [0.62618742, 0.5550608 , 0.6235862 , 0.65014082, 0.64328071],\n",
              "       [0.69581743, 0.6095119 , 0.64590698, 0.65407309, 0.59454384],\n",
              "       [0.70585754, 0.50004276, 0.50752566, 0.70306326, 0.69977967],\n",
              "       [0.71390863, 0.71465028, 0.56330772, 0.68200733, 0.52634312],\n",
              "       [0.63576615, 0.53048753, 0.55819759, 0.66081984, 0.53309672],\n",
              "       [0.6242695 , 0.61345015, 0.50568527, 0.53266145, 0.53460693],\n",
              "       [0.62307787, 0.53641818, 0.59957118, 0.52027378, 0.54523452],\n",
              "       [0.62142153, 0.54730294, 0.5130619 , 0.66523736, 0.5977733 ],\n",
              "       [0.55564582, 0.59628044, 0.6841265 , 0.61611968, 0.72994383],\n",
              "       [0.53060841, 0.65962896, 0.7086696 , 0.67841914, 0.72544765],\n",
              "       [0.61345812, 0.53499019, 0.61300326, 0.6885134 , 0.69652569],\n",
              "       [0.64158808, 0.58977564, 0.60637584, 0.56290152, 0.62387172],\n",
              "       [0.71798428, 0.55926007, 0.64122578, 0.54851631, 0.72016014],\n",
              "       [0.52963894, 0.52544701, 0.63770415, 0.58169739, 0.56654834],\n",
              "       [0.7031181 , 0.72948896, 0.55162426, 0.55189312, 0.50174417],\n",
              "       [0.58452392, 0.50844395, 0.62969833, 0.56589314, 0.5509031 ],\n",
              "       [0.70573619, 0.70447464, 0.67781299, 0.51532345, 0.50923342],\n",
              "       [0.68436146, 0.60972249, 0.54386876, 0.52739729, 0.66456095],\n",
              "       [0.61873752, 0.54789894, 0.59468182, 0.66892625, 0.68842242],\n",
              "       [0.65404019, 0.72149506, 0.61109806, 0.69009202, 0.5072397 ],\n",
              "       [0.68021758, 0.61667606, 0.65395686, 0.56891968, 0.64067693],\n",
              "       [0.60793148, 0.71299165, 0.59728984, 0.50727754, 0.70480769],\n",
              "       [0.69490976, 0.69243216, 0.67509652, 0.66675344, 0.68068417]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18tsZzidPZ-M"
      },
      "source": [
        "# Model architecture  \n",
        " Will define very simplistic model to have keep it simple for better understanding. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_TFTtXYPZl7",
        "outputId": "a8cbec5c-16ea-4bfa-9f62-fcb7f237c485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "input=Input(shape=(x_train.shape[1],)) # it should be equal to the number of columns of x_train\n",
        "\n",
        "x=Dense(10,activation='relu')(input)\n",
        "x=Dense(10,activation='tanh')(x)\n",
        "out=Dense(2,activation=custom_act)(input)\n",
        "\n",
        "model=Model(inputs=input,outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_33 (InputLayer)        [(None, 5)]               0         \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 2)                 12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htHF_at2fy9Z"
      },
      "source": [
        "# Binary Crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Nnl6VGfyLK"
      },
      "source": [
        "import tensorflow as tf \n",
        "def cus_binary_cross_entropy(y_true,y_pred):\n",
        "  y_true=K.cast(y_true,'float32')\n",
        "  y_pred=K.cast(y_pred,'float32')\n",
        "  loss1=y_true[:,0]*K.log(y_pred[:,0]+K.epsilon())+(1-y_true[:,0])*K.log(1-y_pred[:,0]+K.epsilon())\n",
        "  loss2=y_true[:,1]*K.log(y_pred[:,1]+K.epsilon())+(1-y_true[:,1])*K.log(1-y_pred[:,1]+K.epsilon())\n",
        "  return -K.mean(loss1)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkHPYVMpg4IH",
        "outputId": "ff88cfb5-7577-44e3-ade4-7b3b2704a07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss=cus_binary_cross_entropy,optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(x_train,y_train[:,:2], epochs=100,validation_split=.3,verbose=1,batch_size=100)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.7496 - accuracy: 0.5714 - val_loss: 0.7170 - val_accuracy: 0.6333\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7490 - accuracy: 0.5714 - val_loss: 0.7167 - val_accuracy: 0.6333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7485 - accuracy: 0.5714 - val_loss: 0.7164 - val_accuracy: 0.6333\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7479 - accuracy: 0.5714 - val_loss: 0.7162 - val_accuracy: 0.6333\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7474 - accuracy: 0.5714 - val_loss: 0.7159 - val_accuracy: 0.6333\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7469 - accuracy: 0.5714 - val_loss: 0.7157 - val_accuracy: 0.6333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7463 - accuracy: 0.5714 - val_loss: 0.7154 - val_accuracy: 0.6333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7458 - accuracy: 0.5714 - val_loss: 0.7152 - val_accuracy: 0.6333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7453 - accuracy: 0.5714 - val_loss: 0.7150 - val_accuracy: 0.6333\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7448 - accuracy: 0.5714 - val_loss: 0.7147 - val_accuracy: 0.6333\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7443 - accuracy: 0.5714 - val_loss: 0.7145 - val_accuracy: 0.6333\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7437 - accuracy: 0.5714 - val_loss: 0.7142 - val_accuracy: 0.6333\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7432 - accuracy: 0.5714 - val_loss: 0.7140 - val_accuracy: 0.6333\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7427 - accuracy: 0.5714 - val_loss: 0.7138 - val_accuracy: 0.6333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7422 - accuracy: 0.5714 - val_loss: 0.7136 - val_accuracy: 0.6333\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7417 - accuracy: 0.5714 - val_loss: 0.7133 - val_accuracy: 0.6333\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7412 - accuracy: 0.5714 - val_loss: 0.7131 - val_accuracy: 0.6333\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7407 - accuracy: 0.5714 - val_loss: 0.7129 - val_accuracy: 0.6333\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7403 - accuracy: 0.5714 - val_loss: 0.7127 - val_accuracy: 0.6333\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7398 - accuracy: 0.5714 - val_loss: 0.7125 - val_accuracy: 0.6333\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7393 - accuracy: 0.5714 - val_loss: 0.7123 - val_accuracy: 0.6333\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7388 - accuracy: 0.5714 - val_loss: 0.7121 - val_accuracy: 0.6333\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7383 - accuracy: 0.5714 - val_loss: 0.7119 - val_accuracy: 0.6333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7379 - accuracy: 0.5714 - val_loss: 0.7117 - val_accuracy: 0.6333\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7374 - accuracy: 0.5714 - val_loss: 0.7115 - val_accuracy: 0.6333\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7369 - accuracy: 0.5714 - val_loss: 0.7113 - val_accuracy: 0.6333\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7365 - accuracy: 0.5714 - val_loss: 0.7111 - val_accuracy: 0.6333\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7360 - accuracy: 0.5714 - val_loss: 0.7109 - val_accuracy: 0.6333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7356 - accuracy: 0.5857 - val_loss: 0.7108 - val_accuracy: 0.6333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7351 - accuracy: 0.5857 - val_loss: 0.7106 - val_accuracy: 0.6333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7347 - accuracy: 0.5857 - val_loss: 0.7104 - val_accuracy: 0.6333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7343 - accuracy: 0.5857 - val_loss: 0.7102 - val_accuracy: 0.6333\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7338 - accuracy: 0.5857 - val_loss: 0.7101 - val_accuracy: 0.6333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7334 - accuracy: 0.5857 - val_loss: 0.7099 - val_accuracy: 0.6333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7330 - accuracy: 0.5857 - val_loss: 0.7097 - val_accuracy: 0.6333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7325 - accuracy: 0.5857 - val_loss: 0.7096 - val_accuracy: 0.6333\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7321 - accuracy: 0.6000 - val_loss: 0.7094 - val_accuracy: 0.6333\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7317 - accuracy: 0.6000 - val_loss: 0.7093 - val_accuracy: 0.6333\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7313 - accuracy: 0.6000 - val_loss: 0.7091 - val_accuracy: 0.6333\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7309 - accuracy: 0.6000 - val_loss: 0.7090 - val_accuracy: 0.6333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7305 - accuracy: 0.6000 - val_loss: 0.7088 - val_accuracy: 0.6333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7301 - accuracy: 0.5857 - val_loss: 0.7087 - val_accuracy: 0.6333\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7297 - accuracy: 0.5857 - val_loss: 0.7085 - val_accuracy: 0.6333\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7293 - accuracy: 0.5857 - val_loss: 0.7084 - val_accuracy: 0.6333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7289 - accuracy: 0.5857 - val_loss: 0.7083 - val_accuracy: 0.6333\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7285 - accuracy: 0.5857 - val_loss: 0.7081 - val_accuracy: 0.6333\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7281 - accuracy: 0.5857 - val_loss: 0.7080 - val_accuracy: 0.6333\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7278 - accuracy: 0.6000 - val_loss: 0.7079 - val_accuracy: 0.6333\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7274 - accuracy: 0.6000 - val_loss: 0.7078 - val_accuracy: 0.6333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7270 - accuracy: 0.6000 - val_loss: 0.7076 - val_accuracy: 0.6333\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7267 - accuracy: 0.6000 - val_loss: 0.7075 - val_accuracy: 0.6333\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7263 - accuracy: 0.6000 - val_loss: 0.7074 - val_accuracy: 0.6333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7259 - accuracy: 0.6000 - val_loss: 0.7073 - val_accuracy: 0.6333\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7256 - accuracy: 0.6000 - val_loss: 0.7072 - val_accuracy: 0.6333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7252 - accuracy: 0.6000 - val_loss: 0.7071 - val_accuracy: 0.6333\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7249 - accuracy: 0.6000 - val_loss: 0.7070 - val_accuracy: 0.6333\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7245 - accuracy: 0.6000 - val_loss: 0.7069 - val_accuracy: 0.6333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7242 - accuracy: 0.6000 - val_loss: 0.7068 - val_accuracy: 0.6333\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7239 - accuracy: 0.6143 - val_loss: 0.7067 - val_accuracy: 0.6333\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7235 - accuracy: 0.6143 - val_loss: 0.7066 - val_accuracy: 0.6333\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7232 - accuracy: 0.6143 - val_loss: 0.7065 - val_accuracy: 0.6333\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7229 - accuracy: 0.6143 - val_loss: 0.7064 - val_accuracy: 0.6333\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7225 - accuracy: 0.6143 - val_loss: 0.7063 - val_accuracy: 0.6333\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7222 - accuracy: 0.6143 - val_loss: 0.7062 - val_accuracy: 0.6333\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7219 - accuracy: 0.6143 - val_loss: 0.7061 - val_accuracy: 0.6333\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7216 - accuracy: 0.6143 - val_loss: 0.7061 - val_accuracy: 0.6333\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7213 - accuracy: 0.6143 - val_loss: 0.7060 - val_accuracy: 0.6333\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7210 - accuracy: 0.6143 - val_loss: 0.7059 - val_accuracy: 0.6333\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7207 - accuracy: 0.6143 - val_loss: 0.7058 - val_accuracy: 0.6333\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7204 - accuracy: 0.6143 - val_loss: 0.7058 - val_accuracy: 0.6333\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7201 - accuracy: 0.6143 - val_loss: 0.7057 - val_accuracy: 0.6333\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7198 - accuracy: 0.6143 - val_loss: 0.7056 - val_accuracy: 0.6333\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7195 - accuracy: 0.6143 - val_loss: 0.7056 - val_accuracy: 0.6333\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7192 - accuracy: 0.6143 - val_loss: 0.7055 - val_accuracy: 0.6333\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7189 - accuracy: 0.6143 - val_loss: 0.7054 - val_accuracy: 0.6333\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7187 - accuracy: 0.6143 - val_loss: 0.7054 - val_accuracy: 0.6333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7184 - accuracy: 0.6143 - val_loss: 0.7053 - val_accuracy: 0.6333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7181 - accuracy: 0.6286 - val_loss: 0.7053 - val_accuracy: 0.6333\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7178 - accuracy: 0.6286 - val_loss: 0.7052 - val_accuracy: 0.6333\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7176 - accuracy: 0.6143 - val_loss: 0.7052 - val_accuracy: 0.6333\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7173 - accuracy: 0.6143 - val_loss: 0.7051 - val_accuracy: 0.6333\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7170 - accuracy: 0.6143 - val_loss: 0.7051 - val_accuracy: 0.6333\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7168 - accuracy: 0.6143 - val_loss: 0.7050 - val_accuracy: 0.6333\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7165 - accuracy: 0.6143 - val_loss: 0.7050 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7163 - accuracy: 0.6143 - val_loss: 0.7049 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7160 - accuracy: 0.6143 - val_loss: 0.7049 - val_accuracy: 0.6667\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7158 - accuracy: 0.6143 - val_loss: 0.7049 - val_accuracy: 0.6667\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7155 - accuracy: 0.6143 - val_loss: 0.7048 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7153 - accuracy: 0.6143 - val_loss: 0.7048 - val_accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7151 - accuracy: 0.6143 - val_loss: 0.7048 - val_accuracy: 0.6667\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7148 - accuracy: 0.6143 - val_loss: 0.7047 - val_accuracy: 0.6667\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7146 - accuracy: 0.6286 - val_loss: 0.7047 - val_accuracy: 0.6667\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7144 - accuracy: 0.6286 - val_loss: 0.7047 - val_accuracy: 0.6667\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7141 - accuracy: 0.6286 - val_loss: 0.7047 - val_accuracy: 0.6667\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7139 - accuracy: 0.6286 - val_loss: 0.7046 - val_accuracy: 0.6667\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7137 - accuracy: 0.6286 - val_loss: 0.7046 - val_accuracy: 0.6667\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7135 - accuracy: 0.6286 - val_loss: 0.7046 - val_accuracy: 0.6667\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7133 - accuracy: 0.6286 - val_loss: 0.7046 - val_accuracy: 0.6667\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7131 - accuracy: 0.6286 - val_loss: 0.7046 - val_accuracy: 0.6667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7129 - accuracy: 0.6286 - val_loss: 0.7046 - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e1a3acf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf8eRRHN4xuN",
        "outputId": "07d90130-5609-46a6-e2f7-9159c25c5608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x=np.array((.2,.6,.7,.8))\n",
        "np.array((K.sigmoid(x[0]),K.sigmoid(x[1])))\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.549834  , 0.64565631])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    }
  ]
}